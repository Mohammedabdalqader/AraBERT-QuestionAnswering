{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is used to pre-train AraElectra on a specific domain dataset that will later be used for a downtask problem, such as a question answering system.\n",
    "### The code uses Tensorflow 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "from src.pretraining.preprocess import ArabertPreprocessor\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Tensorflow pretrained model from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-10-11 22:09:32--  https://huggingface.co/aubmindlab/araelectra-base-discriminator/resolve/main/tf1_model.tar.gz\n",
      "Auflösen des Hostnamens huggingface.co (huggingface.co) … 2600:1f18:147f:e850:6f3d:1caa:26e9:1d53, 2600:1f18:147f:e800:3e44:323f:9748:7184, 2600:1f18:147f:e800:8b16:ea06:2538:561f, ...\n",
      "Verbindungsaufbau zu huggingface.co (huggingface.co)|2600:1f18:147f:e850:6f3d:1caa:26e9:1d53|:443 … verbunden.\n",
      "HTTP-Anforderung gesendet, auf Antwort wird gewartet … 302 Found\n",
      "Platz: https://cdn-lfs.huggingface.co/aubmindlab/araelectra-base-discriminator/cbca4d0cedf32683a99a235494e946ba11a373095f4040260e005948c88f2af1?response-content-disposition=attachment%3B%20filename%3D%22tf1_model.tar.gz%22&Expires=1665778174&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL2F1Ym1pbmRsYWIvYXJhZWxlY3RyYS1iYXNlLWRpc2NyaW1pbmF0b3IvY2JjYTRkMGNlZGYzMjY4M2E5OWEyMzU0OTRlOTQ2YmExMWEzNzMwOTVmNDA0MDI2MGUwMDU5NDhjODhmMmFmMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMnRmMV9tb2RlbC50YXIuZ3olMjIiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2NjU3NzgxNzR9fX1dfQ__&Signature=pkWnv62f5E8JUh1vqxn8pOqOWxY9-W-Zq16RQ9HPFhBSzLp9P6~-Swtm-3FCWiCawvQq5nHon05u7lpO2lQpkypRWJL8v2ZTHbvuuOShlkyjhr6Kufanai9Wc8PF8I4MiLgc8XwxMkxCferbyP0NpFHQSCZ7n5vMvIU1-co8wTAA0RDh7CQJhmXwIkAX5zAs8A9xXij9HIYOGsoS-xheQszjxPbq3pxol498fOOv5xBR3AKV4kE2GPsARZmH2iuNkTszYybrsvXX8dPAKkfTWy1XVwtDec7O2XUqyxJCrAs~JZ0UIPoI04d4yKa6zRDsdhT9UcmGghaGm8Ni68qYOA__&Key-Pair-Id=KVTP0A1DKRTAX [folgend]\n",
      "--2022-10-11 22:09:33--  https://cdn-lfs.huggingface.co/aubmindlab/araelectra-base-discriminator/cbca4d0cedf32683a99a235494e946ba11a373095f4040260e005948c88f2af1?response-content-disposition=attachment%3B%20filename%3D%22tf1_model.tar.gz%22&Expires=1665778174&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL2F1Ym1pbmRsYWIvYXJhZWxlY3RyYS1iYXNlLWRpc2NyaW1pbmF0b3IvY2JjYTRkMGNlZGYzMjY4M2E5OWEyMzU0OTRlOTQ2YmExMWEzNzMwOTVmNDA0MDI2MGUwMDU5NDhjODhmMmFmMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMnRmMV9tb2RlbC50YXIuZ3olMjIiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2NjU3NzgxNzR9fX1dfQ__&Signature=pkWnv62f5E8JUh1vqxn8pOqOWxY9-W-Zq16RQ9HPFhBSzLp9P6~-Swtm-3FCWiCawvQq5nHon05u7lpO2lQpkypRWJL8v2ZTHbvuuOShlkyjhr6Kufanai9Wc8PF8I4MiLgc8XwxMkxCferbyP0NpFHQSCZ7n5vMvIU1-co8wTAA0RDh7CQJhmXwIkAX5zAs8A9xXij9HIYOGsoS-xheQszjxPbq3pxol498fOOv5xBR3AKV4kE2GPsARZmH2iuNkTszYybrsvXX8dPAKkfTWy1XVwtDec7O2XUqyxJCrAs~JZ0UIPoI04d4yKa6zRDsdhT9UcmGghaGm8Ni68qYOA__&Key-Pair-Id=KVTP0A1DKRTAX\n",
      "Auflösen des Hostnamens cdn-lfs.huggingface.co (cdn-lfs.huggingface.co) … 2600:9000:2315:b000:11:f807:5180:93a1, 2600:9000:2315:fe00:11:f807:5180:93a1, 2600:9000:2315:ec00:11:f807:5180:93a1, ...\n",
      "Verbindungsaufbau zu cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|2600:9000:2315:b000:11:f807:5180:93a1|:443 … verbunden.\n",
      "HTTP-Anforderung gesendet, auf Antwort wird gewartet … 200 OK\n",
      "Länge: 538931319 (514M) [application/x-gzip]\n",
      "Wird in »araelectra-base-discriminator/tf1_model.tar.gz« gespeichert.\n",
      "\n",
      "araelectra-base-dis 100%[===================>] 513,96M  1,55MB/s    in 9m 36s  \n",
      "\n",
      "2022-10-11 22:19:18 (914 KB/s) - »araelectra-base-discriminator/tf1_model.tar.gz« gespeichert [538931319/538931319]\n",
      "\n",
      "tf-araelectra-base/\n",
      "tf-araelectra-base/model.ckpt.data-00000-of-00001\n",
      "tf-araelectra-base/vocab.txt\n",
      "tf-araelectra-base/model.ckpt.index\n",
      "tf-araelectra-base/checkpoint\n",
      "tf-araelectra-base/model.ckpt.meta\n"
     ]
    }
   ],
   "source": [
    "!wget https://huggingface.co/aubmindlab/araelectra-base-discriminator/resolve/main/tf1_model.tar.gz -O araelectra-base-discriminator/tf1_model.tar.gz\n",
    "!tar -xvf araelectra-base-discriminator/tf1_model.tar.gz -C araelectra-base-discriminator/\n",
    "!rm araelectra-base-discriminator/tf1_model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the dataset with farasa_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "يعود تاريخ وزارة الإسكان والتخطيط العمراني إلى العام 1975 ، عندما أصدر صاحب السمو الشيخ عيسى بن سلمان آل خليفة أمير دولة البحرين – طيب الله ثراه .\n"
     ]
    }
   ],
   "source": [
    "model_name = \"aubmindlab/araelectra-base-discriminator\"\n",
    "sample_text = \"dataset/pretraining-dataset/iskan.txt\"\n",
    "sample_text_output_after_farasa_segmentation = \"dataset/pretraining-dataset/iskan_farasa_segmentation.txt\"\n",
    "\n",
    "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
    "\n",
    "with open(sample_text, \"r\") as f:\n",
    "    data = [d.strip(\"\\n\") for d in f.readlines()]\n",
    "\n",
    "with open(sample_text_output_after_farasa_segmentation, \"w\") as f:\n",
    "    for sample in data:\n",
    "        f.write(arabert_prep.preprocess(sample) +\"\\n\")\n",
    "\n",
    "# Here is how the sample after farasa segmentation looks like\n",
    "print(arabert_prep.preprocess(data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data for pretraining AraElectra. This will convert the dataset in an expected format which is \".tfrecord\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:tensorflow:From src/pretraining/create_pretraining_data.py:534: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From src/pretraining/create_pretraining_data.py:534: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From src/pretraining/create_pretraining_data.py:488: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W1011 22:22:55.196787 140434982973632 module_wrapper.py:139] From src/pretraining/create_pretraining_data.py:488: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From src/pretraining/create_pretraining_data.py:488: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W1011 22:22:55.196874 140434982973632 module_wrapper.py:139] From src/pretraining/create_pretraining_data.py:488: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mohammed/AraBERT-QuestionAnswering/src/pretraining/tokenization.py:129: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From src/pretraining/create_pretraining_data.py:498: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "WARNING:tensorflow:From src/pretraining/create_pretraining_data.py:500: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:*** Reading from input files ***\n",
      "INFO:tensorflow:  ./dataset/pretraining-dataset/iskan_farasa_segmentation.txt\n",
      "INFO:tensorflow:*** Writing to output files ***\n",
      "INFO:tensorflow:  ./dataset/pretraining-dataset/iskan.tfrecord\n",
      "WARNING:tensorflow:From src/pretraining/create_pretraining_data.py:118: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] وقد [MASK] اوامر صاحب السمو الملكي الامير [MASK] بن حمد ال خليفة ولي العهد ناي [MASK] القا ##يد الاعلى [MASK] ##يب . الاول لري [MASK] مجلس [MASK] المتتالية بتوزيع [MASK] الاسكانية منذ منتصف عام 2016 ، والمساحات ##ضيف مكتسب ##ا اسكان ##يا جديدا . [SEP] الاسكان [UNUSED_1316] العمراني عام 1975 ، لتب ##دا المملكة مرحلة جديدة في تخطيط . وتنفيذ [MASK] مشاريع السكن الاجتماعي ، وكان [MASK] ابرز سمات تلك [MASK] تخطيط وانشاء مشروع مدينة حمد . كواحد من [MASK] المشاريع التي وفرت مجتمعا ونسي ##جا جديدا من مواطني مختلف محافظات المملكة . [SEP]\n",
      "INFO:tensorflow:input_ids: 2 753 4 38679 1615 2314 2657 1487 4 463 2239 298 4107 1033 3747 57970 4 7018 334 9407 4 739 20 1509 40311 4 714 4 21991 11688 4 42878 794 4241 515 6650 103 57535 2018 45123 181 57472 333 4908 20 3 20010 61316 14018 515 15192 103 36998 465 1282 2823 1252 305 13724 20 9080 4 3254 7328 2803 103 957 4 7545 22714 968 4 13724 25435 1458 1171 2239 20 52729 306 4 2767 376 20973 33348 57519 489 4908 306 9738 1259 8277 1282 20 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 2 8 10 16 20 25 27 30 37 47 61 67 71 80 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 3557 4155 2239 225 686 358 1204 2767 504 15216 9629 306 1827 4533 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] وقد ارت ##ات القيادة الرشيدة والحكومة الموقرة الحاجة الى تاس ##يس وزارة تعنى بادارة شيو ##ن الاسكان . [MASK] تقديم الخدمات [MASK] وفق نهج موس ##سي ، وعليه فقد صدر مرسوم امير [MASK] بت ##اس [MASK] وزارة . [SEP] الاسكان [MASK] العمراني عام 1975 ، لتب ##دا [MASK] مرحلة جديدة الإخوة تخطيط . وتنفيذ وتوزيع مشاريع السكن [MASK] ، وكان من ابرز سمات [MASK] المرحلة تخطيط [MASK] [MASK] مدينة حمد . كواحد من اكبر المشاريع التي وفرت مجتمعا ونسي ##جا جديدا من مواطني مختلف [MASK] المملكة . [SEP]\n",
      "INFO:tensorflow:input_ids: 2 753 1097 302 3506 11045 9103 42299 5046 401 26400 358 1014 12630 31751 20580 186 20010 20 4 1809 2273 4 2505 11988 2188 406 103 9269 1166 3699 13417 3909 4 579 1006 4 1014 20 3 20010 4 14018 515 15192 103 36998 465 4 2823 1252 24013 13724 20 9080 9629 3254 7328 4 103 957 306 7545 22714 4 1827 13724 4 4 1171 2239 20 52729 306 4533 2767 376 20973 33348 57519 489 4908 306 9738 1259 4 1282 20 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 19 22 33 36 41 48 51 58 64 65 67 68 85 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 2159 42878 193 358 15216 1282 305 2803 968 1827 25435 1458 8277 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] في اطار حرص وزارة الاسكان [MASK] [MASK] وسا ##يل الاتصال مع المواطنين [MASK] والتزام الحكومة . بتسهيل اجراءات المواطنين ، طورت الوزارة موقعها الالكتروني ليشمل اتاحة الخدمات الالكترونية . يتيح لك الموقع تقديم [MASK] اسكان جديد الكترونيا ، وتحديث طلب السكن معللا بك . ، والاست ##فسار او الصيانة ، بالاضافة الى الحصول على خرا ##يط الوحدات السكنية ونماذج [MASK] . كما يوفر الموقع جميع المعلومات المتعلقة بالوزارة معارضة كانت مشاريعها او مدنها الجديدة . يمكنك ايضا [MASK] على معلومات حول احدث مشاريع وخدمات الوزارة من خلال زيارة المركز [MASK] . [SEP] بهدف تقديم [MASK] الاسكانية وفق نهج موس ##سي ، وعليه [MASK] صدر مرسوم امير ##ي [MASK] ##اس ##يس وزارة . الاسكان [MASK] العمراني عام [MASK] ، لتب ##دا المملكة مرحلة جديدة في تخطيط [MASK] [SEP]\n",
      "INFO:tensorflow:input_ids: 2 305 4616 3656 1014 20010 4 4 12189 349 4611 354 1887 4 17592 888 20 36176 7846 1887 103 34971 1962 10555 9258 24416 41060 2273 8758 20 9836 1882 2927 1809 4 57472 1463 38427 103 18795 1667 7328 46835 1607 20 103 1908 21298 893 10919 103 4504 401 2850 323 55076 1036 6486 5279 49709 4 20 547 9064 2927 906 2093 3787 14548 9326 678 25301 893 57483 1594 20 16772 2285 4 323 3067 795 16315 3254 13410 1962 306 492 2764 1203 4 20 3 2159 1809 4 42878 2505 11988 2188 406 103 9269 4 3699 13417 3909 193 4 1006 358 1014 20 20010 4 14018 515 4 103 36998 465 1282 2823 1252 305 13724 4 3\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 6 7 13 34 42 45 48 57 60 69 76 78 90 95 103 108 114 117 126 0\n",
      "INFO:tensorflow:masked_lm_ids: 323 2226 103 1667 1848 103 893 6486 8469 2044 16772 2850 11197 2273 1166 579 15216 15192 20 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] تمثل في حصول ما يزيد عن 25 الف [MASK] بحرينية على سكنه ##ا [MASK] فترة زمنية وجيزة ، في ترجمة واضحة لجهود المملكة في هذا الشان [MASK] [SEP] ##هداف ذلك متزامنا مع [MASK] ##ات مدن البحرين [MASK] التي تم تشغيل 4 منها حتى وقتنا هذا ، الامر الذي يجسد [MASK] العمل المنجز [MASK] [SEP]\n",
      "INFO:tensorflow:input_ids: 2 3228 305 4473 394 3837 352 1540 357 4 59064 323 54136 181 4 1819 12873 17437 103 305 10227 4131 14003 1282 305 434 29126 4 3 1441 563 53936 354 4 302 5432 3949 4 376 513 6276 25 995 655 30394 434 103 3253 425 16642 4 700 47194 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 9 14 27 29 33 37 50 53 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 20757 305 20 3015 3721 1594 2493 20 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] على تطوير وسا ##يل الاتصال مع المواطنين ، والتزام الحكومة . بتسهيل اجراءات المواطنين ، طورت الوزارة موقعها الالكتروني ليشمل اتاحة الخدمات الالكترونية . يتيح لك الموقع تقديم طلب اسكان جديد الكترونيا ، وتحديث طلب [MASK] الخاص بك . [UNUSED_3242] والاست ##فسار [MASK] الصيانة ، بالاضافة الى الحصول على خرا ##يط الوحدات السكنية ونماذج المباني [MASK] كما يوفر الموقع [MASK] المعلومات المتعلقة بالوزارة سواء [MASK] مشاريعها او [MASK] الجديدة . يمكنك ايضا الحصول والمستندات معلومات حول احدث مشاريع وخدمات الوزارة من خلال زيارة المركز [MASK] [MASK] ويمكن ##ك حتى ارسال [MASK] [MASK] اقتراحات للوزارة من خلال برامج تواصل [MASK] نام ##ل ان نل ##بي [MASK] [MASK] عندما [SEP] ومع استمرار [MASK] عدد الطلبات والحاجة الى مواكبة متطلبات العصر الحديث ، امر حضرة صاحب الجلالة الملك . [SEP]\n",
      "INFO:tensorflow:input_ids: 2 323 2226 12189 349 4611 354 1887 103 17592 888 20 36176 7846 1887 103 34971 1962 10555 9258 24416 41060 2273 8758 20 9836 1882 2927 1809 1667 57472 1463 38427 103 18795 1667 4 1848 1607 20 63242 1908 21298 4 10919 103 4504 401 2850 323 55076 1036 6486 5279 49709 8469 4 547 9064 2927 4 2093 3787 14548 2044 4 25301 893 4 1594 20 16772 2285 2850 35618 3067 795 16315 3254 13410 1962 306 492 2764 1203 4 4 4485 209 655 13100 4 4 19326 14351 306 492 3221 5129 4 24310 182 338 13151 390 4 4 1153 3 1477 3002 4 750 12299 29313 401 16751 7759 5744 2740 103 6177 29485 1615 32918 1089 20 3\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 4 36 40 43 56 60 65 68 72 74 85 86 91 92 98 99 105 106 111 0\n",
      "INFO:tensorflow:masked_lm_ids: 349 7328 103 893 20 906 678 57483 2285 323 11197 20 28490 893 5129 20 6170 209 2001 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] وتقوم وزارة الاسكان والتخطيط العمراني بتوفير ##الع ##ديد من الخدمات الاسكانية للمواطنين في اطار الالتزام . بنص دستور المملكة ##ولاه نص المادة [MASK] 9 الفقرة ( و ) والتي تنص على انه . تعمل [MASK] على توفير السكن لذوي الدخل المحدود من المواطنين ، [MASK] هذه [MASK] . [SEP] خدمة الوحدات السكنية , خدمة شقق التم [MASK] , خدمة القسا ##يم السكنية , خدمة [MASK] ##ات الاسكانية [MASK] بناء , خدمة [MASK] مزايا [MASK] [SEP]\n",
      "INFO:tensorflow:input_ids: 2 10679 1014 20010 15216 14018 10413 25865 477 306 2273 42878 7361 305 4616 5562 20 31790 9409 1282 44251 2295 3129 4 30 11748 14 139 15 1122 10976 323 889 20 2806 4 323 2970 7328 17875 6787 17835 306 1887 103 4 450 4 20 3 2796 6486 5279 18 2796 26612 2625 4 18 2796 58120 381 5279 18 2796 4 302 42878 4 1745 18 2796 4 17613 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 20 23 33 35 45 47 57 65 68 72 74 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 8765 2245 20 975 623 2273 7998 4954 4445 1671 20 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] الادارة على [MASK] قيمة اعلى للمس ##كن ، على ان يلتزم المنت [MASK] . [SEP] بتحمل مس [MASK] ##ية سداد الفرق [MASK] القيمة المحددة للبرنامج [MASK] المسكن منفردا تجاه البنك الممول . [SEP]\n",
      "INFO:tensorflow:input_ids: 2 3332 323 4 2496 12308 5464 410 103 323 338 15185 998 4 20 3 33514 555 4 300 11418 3896 4 5691 9856 17624 4 23667 28359 3030 2483 42473 20 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 3 13 18 22 26 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 3007 675 30633 433 23481 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] الا يقل سنه عند تقديم الطلب وصرف التمويل من الممول عن ##ليقة سنة ولا يزيد [MASK] 35 سنة . الا يقل دخله [MASK] عند تقديم الطلب وصرف التمويل من البنك الممول عن 600 دينار بحريني ولا يزيد عن 1200 دينار بحريني . الا [MASK] [MASK] [MASK] اي [MASK] افراد [MASK] قد سبق لاي منهم الحصول على اي خدمة اسكان [MASK] لغرض تملك مسكن مقدم من الحكومة او اية [MASK] اخرى . [SEP] وجاء ذلك متزامنا مع افتتاح ##ات مدن البحرين [MASK] التي تم تشغيل 4 منها [MASK] وقتنا هذا ، الامر [MASK] [MASK] واردا العمل المنجز . [SEP]\n",
      "INFO:tensorflow:input_ids: 2 335 4366 24276 690 1809 3352 21052 4954 306 42473 352 12367 1283 662 3837 4 3059 1283 20 335 4366 37618 4 690 1809 3352 21052 4954 306 2483 42473 352 8122 3493 44432 662 3837 352 15902 3493 44432 20 335 4 4 4 897 4 9872 4 602 3514 7278 1900 2850 323 897 2796 57472 4 24415 5546 16171 5021 306 888 893 13597 4 2553 20 3 3015 563 53936 354 3721 302 5432 3949 4 376 513 6276 25 995 4 30394 434 103 3253 4 4 51655 700 47194 20 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 12 16 23 44 45 46 48 50 60 69 81 87 92 93 94 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 2366 352 8017 887 583 893 306 40149 300 1984 1594 655 425 16642 2493 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] سنة ولا يزيد عن 35 سنة . الا [MASK] دخله الشهري عند تقديم الطلب وصرف التمويل من البنك الممول عن 600 دينار بحريني ولا يزيد [MASK] 1200 دينار بحريني . [MASK] يكون هو او اي من [MASK] اسرته قد سبق لاي منهم [MASK] على اي خدمة اسكان ##ية لغرض تملك مسكن مقدم من الحكومة او [MASK] [MASK] اخرى . الا يكون مالك ##ا لع ##قار هو او احد سيأتي اسرته عند تقديم الطلب ول 3 سنوات سابقة على ذلك [SEP] [MASK] ##كن عن طريق احدى صيغ التمويل الاسلامي ، ويست ##ثنى التالي [MASK] [MASK] عدم الملكية . ملكية عقار هوت مساحته عن 100 [MASK] مربع على [MASK] [MASK] صالحا للسكن او لبناء مسكن [MASK] ملك الزوجة لع ##قار الت ملكيته لها عن طريق الار ##ث [MASK] [SEP]\n",
      "INFO:tensorflow:input_ids: 2 1283 662 3837 352 3059 1283 20 335 4 37618 8017 690 1809 3352 21052 4954 306 2483 42473 352 8122 3493 44432 662 3837 4 15902 3493 44432 20 4 887 583 893 897 306 4 40149 602 3514 7278 1900 4 323 897 2796 57472 300 24415 5546 16171 5021 306 888 893 4 4 2553 20 335 887 8210 181 1498 7612 583 893 1680 27173 40149 690 1809 3352 611 24 1424 5637 323 563 3 4 410 352 1278 5241 24359 4954 5532 103 3643 30548 5603 4 4 1114 5841 20 13302 16490 30488 26254 352 2638 4 7607 323 4 4 35355 28221 893 7063 16171 4 3852 10866 1498 7612 313 54479 884 352 1278 1285 237 4 3\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 9 26 31 37 43 46 56 57 69 81 93 94 100 103 104 107 108 114 126 0\n",
      "INFO:tensorflow:masked_lm_ids: 4366 352 335 9872 2850 2796 13597 1984 9872 1841 306 8311 4330 2638 3572 335 887 18 20 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] قا ##يم بشكل فردي او من قا ##يمة [MASK] . المعتمدة والمش ##يدة من قبل احد المطورين العقاريين المعتمدين [MASK] على ان تتوافر [MASK] المسكن المعايير الات ##ية . ان يكون مسكن [MASK] [MASK] شبه منفصل او ملت ##صق باخ ##ر ، او مسكن ضمن مجمع سكني او على هي ##ية شقة . [MASK] يكون المسكن حديث البناء او ما دون [MASK] على ان [MASK] صالحا [MASK] لمدة 25 سنة قادمة حسب بقدرته المختصين بالوزارة . [MASK] يتوافق بناء المسكن مع الاشتراطات التنظيمية للتعمير بمختلف [SEP] ان [MASK] المسكن [MASK] للسكن من تاريخ شرا ##يه موص [MASK] بام [MASK] البنية التحتية اللازمة [MASK] كهرباء وماء ومرافق الصرف الصحي . الا [MASK] سعر محلى على القيمة المحددة للبرنامج والبالغة 90 الف دينار بحريني ما لم توافق . [SEP]\n",
      "INFO:tensorflow:input_ids: 2 9045 381 980 18345 893 306 9045 4036 4 20 10786 5306 1063 306 600 1680 43165 33073 30155 4 323 338 16210 4 23667 7861 629 300 20 338 887 16171 4 4 4691 20330 893 8346 17210 21237 183 103 893 16171 1313 6690 30053 893 323 634 300 13087 20 4 887 23667 2643 3654 893 394 873 4 323 338 4 35355 4 2260 1540 1283 11132 1919 46863 14940 14548 20 4 18323 1745 23667 354 31400 11963 52051 8502 3 338 4 23667 4 28221 306 1580 13343 1004 31945 4 11150 4 6623 5713 3356 4 10622 54097 25404 5966 3619 20 335 4 2885 28534 323 5691 9856 17624 21981 4249 357 3493 44432 394 407 8136 20 3\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 9 20 24 33 34 37 54 62 65 67 73 77 88 90 97 99 103 111 113 0\n",
      "INFO:tensorflow:masked_lm_ids: 14300 103 305 20330 893 893 338 563 887 28221 5991 338 887 35355 326 26381 306 3837 23667 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] يزيد عن 35 سنة . الا يقل دخله الشهري عند تقديم الطلب وصرف التمويل من البنك الممول عن 600 [MASK] بحريني [MASK] [MASK] عن 1200 دينار [MASK] [MASK] الا يكون هو او [MASK] من افراد اسرته قد سبق لاي منهم الحصول على [MASK] خدمة اسكان ##ية لغرض تملك مسكن مقدم من الحكومة او اية جهة اخرى . الا يكون [MASK] [MASK] [MASK] ##قار هو او [MASK] افراد [MASK] عند تقديم الطلب ول 3 سنوات سابقة على ذلك والى حين التخصيص . ويعتبر في حكم المالك من [MASK] ##فع . بس ##كن [MASK] طريق احدى صيغ التمويل [SEP] ملكية عقار تقل مساحته عن 100 متر مربع [MASK] الا يكون [MASK] للسكن او لبناء مسكن , ملك الزوجة لع [MASK] الت ملكيته [MASK] عن طريق الار ##ث . [SEP]\n",
      "INFO:tensorflow:input_ids: 2 3837 352 3059 1283 20 335 4366 37618 8017 690 1809 3352 21052 4954 306 2483 42473 352 8122 4 44432 4 4 352 15902 3493 4 4 335 887 583 893 4 306 9872 40149 602 3514 7278 1900 2850 323 4 2796 57472 300 24415 5546 16171 5021 306 888 893 13597 1984 2553 20 335 887 4 4 4 7612 583 893 4 9872 4 690 1809 3352 611 24 1424 5637 323 563 6259 1173 26742 20 6339 305 2441 17824 306 4 675 20 1841 410 4 1278 5241 24359 4954 3 13302 16490 4330 26254 352 2638 3572 7607 4 335 887 4 28221 893 7063 16171 18 3852 10866 1498 4 313 54479 4 352 1278 1285 237 20 3\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 20 22 23 27 28 33 43 60 61 62 66 68 87 92 99 106 109 118 121 0\n",
      "INFO:tensorflow:masked_lm_ids: 3493 662 3837 44432 20 897 897 8210 181 1498 1680 40149 740 352 16490 323 35355 7612 884 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] يعود تاريخ وزارة الاسكان والتخطيط العمراني الى العام 1975 ، [MASK] اصدر [MASK] السمو [MASK] عيسى بن سلمان ال خليفة امير دولة البحرين – طيب الله ثراه . [SEP] تعمل الدولة على توفير [MASK] لذوي الدخل المحدود [MASK] المواطنين ، ومن [MASK] الخدمات . خدمة الوحدات السكنية , خدمة شقق التم ##ليك , خدمة القسا ##يم السكنية , خدمة التمويل ##ات الاسكانية شراء بناء , خدمة [MASK] كوشن [MASK] [SEP]\n",
      "INFO:tensorflow:input_ids: 2 3083 1580 1014 20010 15216 14018 401 470 15192 103 4 12543 4 2314 4 5059 463 4155 298 4107 3909 1505 3949 170 6893 647 25092 20 3 2806 975 323 2970 4 17875 6787 17835 4 1887 103 623 4 2273 20 2796 6486 5279 18 2796 26612 2625 7998 18 2796 58120 381 5279 18 2796 4954 302 42878 4445 1745 18 2796 4 26156 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 11 13 15 34 38 42 51 61 67 68 69 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 1153 1615 1158 7328 306 450 2625 302 1671 17613 20 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] يعد ملف الاسكان بمملكة البحرين من ابرز الملفات المعيشية التي تحظى [MASK] ##ولو ##ية لدى المواطن البحريني [MASK] [MASK] ما . وعت اليه ##قطاب الرشيدة منذ عقود طويلة ، وتحديدا منذ مطلع ستينيات القرن الماضي . [MASK] تم الاسلامية ##يس لجنة الاسكان والتم ##ليك عام 1962 ، يطلقون وضعت التشريع الاول [MASK] لسياسة [MASK] تقديم الخدمات الاسكانية للمواطنين ، ليع ##قب ذلك بعام واحد انشاء مشروع مدينة [MASK] كا ##ول مدينة [MASK] [SEP] اسكان ##ية متكاملة في المملكة تلبي احتياجات المواطنين [MASK] [MASK] على السكن . [SEP]\n",
      "INFO:tensorflow:input_ids: 2 2146 3565 20010 49499 3949 306 7545 9391 12515 376 10235 4 10502 300 1309 1322 10768 4 4 394 20 46570 4084 7057 11045 794 4818 2980 103 8765 794 4807 53946 2890 1001 20 4 513 3571 358 1359 20010 6783 7998 515 18495 103 26121 6370 16574 1509 4 20413 4 1809 2273 42878 7361 103 7739 617 563 26994 1411 7267 1458 1171 4 3871 314 1171 4 3 57472 300 9886 305 1282 17967 6170 1887 4 4 323 7328 20 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 12 18 19 24 37 39 48 52 54 68 72 82 83 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 3144 103 747 3506 1153 26400 1122 14635 20 5059 20 305 2850 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] بس ##كن عن طريق احدى صيغ التمويل الاسلامي ، ويست ##ثنى التالي من شرط عدم الملكية . [SEP] اسكان ##ية متكاملة [MASK] المملكة تلبي احتياجات المواطنين [MASK] الحصول على السكن تعديلا [SEP]\n",
      "INFO:tensorflow:input_ids: 2 1841 410 352 1278 5241 24359 4954 5532 103 3643 30548 5603 306 8311 1114 5841 20 3 57472 300 9886 4 1282 17967 6170 1887 4 2850 323 7328 36878 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 9 22 23 27 31 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 103 305 1282 305 20 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] ##يم بشكل فردي [MASK] من قا ##يمة المساكن . المعتمدة والمش ##يدة من قبل احد المطورين العقاريين المعتمدين ، الأحجام ان تتوافر في المسكن المعايير الات ##ية . ان يكون مسكن منفصل او شبه منفصل او [MASK] ##صق باخ ##ر ، او [MASK] ضمن مجمع سكني او على هي ##ية [MASK] . [MASK] يكون المسكن حديث [MASK] او ما دون ذلك على ان يكون صالحا للسكن لمدة 25 سنة قادمة حسب [SEP] ان يتوافق بناء المسكن مع [MASK] التنظيمية للتعمير بمختلف [MASK] في مملكة البحرين . ان يكون [MASK] صالحا للسكن من تاريخ شرا ##يه موص ##لا [MASK] ##دادات البنية التحتية اللازمة من كهرباء وماء ومرافق الصرف الصحي . الا [MASK] سعر [MASK] على القيمة المحددة للبرنامج والبالغة 90 الف دينار بحريني [MASK] [MASK] [MASK] . [SEP]\n",
      "INFO:tensorflow:input_ids: 2 381 980 18345 4 306 9045 4036 14300 20 10786 5306 1063 306 600 1680 43165 33073 30155 103 49561 338 16210 305 23667 7861 629 300 20 338 887 16171 20330 893 4691 20330 893 4 17210 21237 183 103 893 4 1313 6690 30053 893 323 634 300 4 20 4 887 23667 2643 4 893 394 873 563 323 338 887 35355 28221 2260 1540 1283 11132 1919 3 338 18323 1745 23667 354 4 11963 52051 8502 4 305 10576 3949 20 338 887 4 35355 28221 306 1580 13343 1004 31945 326 4 26381 6623 5713 3356 306 10622 54097 25404 5966 3619 20 335 4 2885 4 323 5691 9856 17624 21981 4249 357 3493 44432 4 4 4 20 3\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 4 17 20 37 43 51 53 57 67 78 82 89 98 110 111 113 123 124 125 0\n",
      "INFO:tensorflow:masked_lm_ids: 893 33073 323 8346 16171 13087 338 3654 2260 31400 2136 23667 11150 335 3837 23667 394 407 8136 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] وبرامجها الرامية الى مواصلة نهج تقديم [MASK] الاسكانية للمواطنين ذوي الدخل المحدود . [SEP] مرسوما لانشاء وزارة الاسكان والتخطيط العمراني لتوفير سكن اجتماعي للم ##وطنين من [MASK] الدخل المحدود . و قد تم تعيين [UNUSED_1496] [MASK] بن عبدالله [MASK] خليفة كا ##ول وزير [MASK] . [SEP]\n",
      "INFO:tensorflow:input_ids: 2 36410 12049 401 6342 11988 1809 4 42878 7361 5308 6787 17835 20 3 35207 26153 1014 20010 15216 14018 8541 9305 13919 565 13670 306 4 6787 17835 20 139 602 513 4378 61496 4 463 1098 4 4107 3871 314 902 4 20 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 7 23 27 35 36 39 44 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 2273 13919 5308 1158 1645 298 54934 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] وقد ارت [MASK] القيادة الرشيدة والحكومة الموقرة الحاجة [MASK] تاس ##يس وزارة تعنى بادارة شيو الصدري الاسكان . [MASK] تقديم الخدمات الاسكانية وفق نهج موس ##سي ، وعليه فقد صدر [MASK] امير ##ي بت ##اس ##يس وزارة . [SEP] الاسكان والتخطيط العمراني عام 1975 ، [UNUSED_3283] ##دا المملكة مرحلة جديدة في تخطيط . وتنفيذ وتوزيع مشاريع [MASK] الاجتماعي ، [MASK] من ابرز [MASK] تلك المرحلة تخطيط وانشاء مشروع مدينة حمد . كواحد [MASK] اكبر المشاريع التي وفرت مجتمعا ونسي ##جا جديدا من [MASK] مختلف [MASK] المملكة . [SEP]\n",
      "INFO:tensorflow:input_ids: 2 753 1097 4 3506 11045 9103 42299 5046 4 26400 358 1014 12630 31751 20580 29672 20010 20 4 1809 2273 42878 2505 11988 2188 406 103 9269 1166 3699 4 3909 193 579 1006 358 1014 20 3 20010 15216 14018 515 15192 103 63283 465 1282 2823 1252 305 13724 20 9080 9629 3254 4 2803 103 4 306 7545 4 968 1827 13724 25435 1458 1171 2239 20 52729 4 4533 2767 376 20973 33348 57519 489 4908 306 4 1259 4 1282 20 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 3 9 16 19 31 46 52 57 60 63 73 83 85 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 302 401 186 2159 13417 36998 13724 7328 957 22714 306 9738 8277 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] وبرامجها الرامية [MASK] مواصلة نهج تقديم الخدمات الاسكانية للمواطنين ذوي الدخل المحدود [MASK] [SEP] تقديم الخدمات الاسكانية للمواطنين [MASK] ليع ##قب ذلك بعام [MASK] انشاء مشروع مدينة عيسى [MASK] ##ول مدينة . اسكان ##ية متكاملة والترتيب المملكة تلبي [UNUSED_1312] المواطنين في الحصول على السكن . [SEP]\n",
      "INFO:tensorflow:input_ids: 2 36410 12049 4 6342 11988 1809 2273 42878 7361 5308 6787 17835 4 3 1809 2273 42878 7361 4 7739 617 563 26994 4 7267 1458 1171 5059 4 314 1171 20 57472 300 9886 57330 1282 17967 61312 1887 305 2850 323 7328 20 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 3 13 19 24 29 36 39 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 401 20 103 1411 3871 305 6170 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] [MASK] قوا ##يم الانتظار ، فيما ساهمت المبادرات الاخرى في زيادة عدد المشاريع ، التي استوعب ##ت الالاف من الطلبات الاسكانية . [SEP] في [MASK] معنا عبر الخط [MASK] 800 ##0 ##80 [MASK] او مراسل ##تنا عبر البريد الالكتروني [MASK] [SEP]\n",
      "INFO:tensorflow:input_ids: 2 4 42808 381 11099 103 1059 9370 11827 4820 305 2001 750 2767 103 376 42774 228 35853 306 12299 42878 20 3 305 4 8987 1115 1266 4 8868 188 11313 4 893 10430 2409 1115 8245 9258 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_positions: 1 14 25 29 33 40 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_ids: 323 103 3745 29095 7396 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:tokens: [CLS] كما يوفر الموقع للفريق المعلومات المتعلقة بالوزارة سواء كانت مشاريعها او [MASK] الجديدة . [MASK] ايضا الحصول على معلومات حول احدث [UNUSED_1107] [MASK] الوزارة من [MASK] زيارة المركز الاعلامي . ويمكن ##ك [MASK] ارسال [MASK] او اقتراحات للوزارة من [MASK] برامج تواصل . [SEP] بن [MASK] يعب خليفة ولي العهد ناي ##ب [MASK] ##يد الاعلى النا ##يب [MASK] الاول لري ##يس مجلس الوزراء المتتالية بتوزيع المشاريع الاسكانية منذ منتصف عام 2016 ، لت ##ضيف مكتسب ##ا اسكان ##يا جديدا . تمثل في حصول ما يزيد [MASK] 25 الف اسرة بحرينية على سكنه ##ا في فترة زمنية وجيزة ، في ترجمة أيديولوجية لجهود المملكة في هذا الشان [MASK] وجاء ذلك متزامنا مع افتتاح ##ات [MASK] البحرين الجديدة التي تم تشغيل 4 منها حتى وقتنا هذا ، الامر [SEP]\n",
      "INFO:tensorflow:input_ids: 2 547 9064 2927 4853 2093 3787 14548 2044 678 25301 893 4 1594 20 4 2285 2850 323 3067 795 16315 61107 4 1962 306 4 2764 1203 11197 20 4485 209 4 13100 4 893 19326 14351 306 4 3221 5129 20 3 463 4 34595 4107 1033 3747 57970 225 4 334 9407 686 739 4 1509 40311 358 714 1204 21991 11688 2767 42878 794 4241 515 6650 103 504 2018 45123 181 57472 333 4908 20 3228 305 4473 394 3837 4 1540 357 20757 59064 323 54136 181 305 1819 12873 17437 103 305 10227 54311 14003 1282 305 434 29126 4 3015 563 53936 354 3721 302 4 3949 1594 376 513 6276 25 995 655 30394 434 103 3253 3\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:masked_lm_positions: 4 12 15 21 22 23 26 33 35 40 46 47 53 55 58 86 101 107 114 0\n",
      "INFO:tensorflow:masked_lm_ids: 906 57483 16772 16315 3254 13410 492 655 28490 492 2239 298 7018 9407 20 352 4131 20 5432 0\n",
      "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
      "INFO:tensorflow:next_sentence_labels: 1\n",
      "INFO:tensorflow:Wrote 120 total instances\n"
     ]
    }
   ],
   "source": [
    "!python src/pretraining/create_pretraining_data.py \\\n",
    "  --input_file=./dataset/pretraining-dataset/iskan_farasa_segmentation.txt \\\n",
    "  --output_file=./dataset/pretraining-dataset/iskan.tfrecord \\\n",
    "  --vocab_file=araelectra-base-discriminator/tf-araelectra-base/vocab.txt \\\n",
    "  --do_lower_case=True \\\n",
    "  --max_seq_length=128 \\\n",
    "  --max_predictions_per_seq=20 \\\n",
    "  --masked_lm_prob=0.15 \\\n",
    "  --random_seed=12345 \\\n",
    "  --dupe_factor=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-train/fine-tune AraElectra on a specific domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:tensorflow:From /home/mohammed/AraBERT-QuestionAnswering/src/pretraining/lamb_optimizer.py:36: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mohammed/AraBERT-QuestionAnswering/src/pretraining/lamb_optimizer.py:36: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From src/pretraining/run_pretraining.py:593: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From src/pretraining/run_pretraining.py:593: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From src/pretraining/run_pretraining.py:496: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W1011 22:28:55.030264 139694655488192 module_wrapper.py:139] From src/pretraining/run_pretraining.py:496: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From src/pretraining/run_pretraining.py:496: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W1011 22:28:55.030861 139694655488192 module_wrapper.py:139] From src/pretraining/run_pretraining.py:496: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mohammed/AraBERT-QuestionAnswering/src/pretraining/modeling.py:94: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From src/pretraining/run_pretraining.py:505: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "WARNING:tensorflow:From src/pretraining/run_pretraining.py:509: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f0cc027f200>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'pretraining_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 10, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0ca4b178d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
      "WARNING:tensorflow:From src/pretraining/run_pretraining.py:559: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:***** Running training *****\n",
      "INFO:tensorflow:  Batch size = 2\n",
      "WARNING:tensorflow:From /home/mohammed/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/mohammed/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From src/pretraining/run_pretraining.py:424: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From src/pretraining/run_pretraining.py:453: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "WARNING:tensorflow:From /home/mohammed/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From src/pretraining/run_pretraining.py:472: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "WARNING:tensorflow:From /home/mohammed/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From /home/mohammed/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From src/pretraining/run_pretraining.py:489: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running train on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (2, 128)\n",
      "INFO:tensorflow:  name = input_mask, shape = (2, 128)\n",
      "INFO:tensorflow:  name = masked_lm_ids, shape = (2, 20)\n",
      "INFO:tensorflow:  name = masked_lm_positions, shape = (2, 20)\n",
      "INFO:tensorflow:  name = masked_lm_weights, shape = (2, 20)\n",
      "INFO:tensorflow:  name = next_sentence_labels, shape = (2, 1)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (2, 128)\n",
      "WARNING:tensorflow:From /home/mohammed/AraBERT-QuestionAnswering/src/pretraining/modeling.py:167: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mohammed/AraBERT-QuestionAnswering/src/pretraining/modeling.py:401: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mohammed/AraBERT-QuestionAnswering/src/pretraining/modeling.py:484: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mohammed/AraBERT-QuestionAnswering/src/pretraining/modeling.py:349: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/mohammed/AraBERT-QuestionAnswering/src/pretraining/modeling.py:663: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/mohammed/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From src/pretraining/run_pretraining.py:202: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From src/pretraining/run_pretraining.py:219: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (64000, 768)\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = cls/predictions/transform/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = cls/predictions/output_bias:0, shape = (64000,)\n",
      "INFO:tensorflow:  name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n",
      "INFO:tensorflow:  name = cls/seq_relationship/output_bias:0, shape = (2,)\n",
      "WARNING:tensorflow:From /home/mohammed/AraBERT-QuestionAnswering/src/pretraining/optimization.py:29: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mohammed/AraBERT-QuestionAnswering/src/pretraining/optimization.py:34: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n",
      "INFO:tensorflow:++++++ warmup starts at step 0, for 10 steps ++++++\n",
      "INFO:tensorflow:using lamb\n",
      "WARNING:tensorflow:From /home/mohammed/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2022-10-11 22:29:12.219685: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-10-11 22:29:13.452444: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599990000 Hz\n",
      "2022-10-11 22:29:13.791753: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bfd180f050 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-10-11 22:29:13.791888: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-10-11 22:29:14.097269: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-10-11 22:29:14.304682: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-10-11 22:29:14.304850: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mohammed-GL75-Leopard-10SFR\n",
      "2022-10-11 22:29:14.304898: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mohammed-GL75-Leopard-10SFR\n",
      "2022-10-11 22:29:14.305161: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.57.2\n",
      "2022-10-11 22:29:14.305262: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.57.2\n",
      "2022-10-11 22:29:14.305293: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 470.57.2\n",
      "INFO:tensorflow:Restoring parameters from pretraining_output/model.ckpt-0\n",
      "WARNING:tensorflow:From /home/mohammed/anaconda3/envs/python37/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into pretraining_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.179285\n",
      "INFO:tensorflow:examples/sec: 0.358569\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1 vs previous value: 1. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 0.527377\n",
      "INFO:tensorflow:examples/sec: 1.05475\n",
      "INFO:tensorflow:global_step/sec: 0.54359\n",
      "INFO:tensorflow:examples/sec: 1.08718\n",
      "INFO:tensorflow:global_step/sec: 0.546138\n",
      "INFO:tensorflow:examples/sec: 1.09228\n",
      "INFO:tensorflow:global_step/sec: 0.533041\n",
      "INFO:tensorflow:examples/sec: 1.06608\n",
      "INFO:tensorflow:global_step/sec: 0.546162\n",
      "INFO:tensorflow:examples/sec: 1.09232\n",
      "INFO:tensorflow:global_step/sec: 0.550388\n",
      "INFO:tensorflow:examples/sec: 1.10078\n",
      "INFO:tensorflow:global_step/sec: 0.535366\n",
      "INFO:tensorflow:examples/sec: 1.07073\n",
      "INFO:tensorflow:global_step/sec: 0.507959\n",
      "INFO:tensorflow:examples/sec: 1.01592\n",
      "INFO:tensorflow:global_step/sec: 0.501907\n",
      "INFO:tensorflow:examples/sec: 1.00381\n",
      "INFO:tensorflow:global_step/sec: 0.534729\n",
      "INFO:tensorflow:examples/sec: 1.06946\n",
      "INFO:tensorflow:global_step/sec: 0.551517\n",
      "INFO:tensorflow:examples/sec: 1.10303\n",
      "INFO:tensorflow:global_step/sec: 0.549092\n",
      "INFO:tensorflow:examples/sec: 1.09818\n",
      "INFO:tensorflow:global_step/sec: 0.551744\n",
      "INFO:tensorflow:examples/sec: 1.10349\n",
      "INFO:tensorflow:global_step/sec: 0.549789\n",
      "INFO:tensorflow:examples/sec: 1.09958\n",
      "INFO:tensorflow:global_step/sec: 0.548647\n",
      "INFO:tensorflow:examples/sec: 1.09729\n",
      "INFO:tensorflow:global_step/sec: 0.536744\n",
      "INFO:tensorflow:examples/sec: 1.07349\n",
      "INFO:tensorflow:global_step/sec: 0.550645\n",
      "INFO:tensorflow:examples/sec: 1.10129\n",
      "INFO:tensorflow:global_step/sec: 0.540884\n",
      "INFO:tensorflow:examples/sec: 1.08177\n",
      "INFO:tensorflow:global_step/sec: 0.565361\n",
      "INFO:tensorflow:examples/sec: 1.13072\n",
      "INFO:tensorflow:global_step/sec: 0.566201\n",
      "INFO:tensorflow:examples/sec: 1.1324\n",
      "INFO:tensorflow:global_step/sec: 0.56841\n",
      "INFO:tensorflow:examples/sec: 1.13682\n",
      "INFO:tensorflow:global_step/sec: 0.569682\n",
      "INFO:tensorflow:examples/sec: 1.13936\n",
      "INFO:tensorflow:global_step/sec: 0.568463\n",
      "INFO:tensorflow:examples/sec: 1.13693\n",
      "INFO:tensorflow:global_step/sec: 0.568025\n",
      "INFO:tensorflow:examples/sec: 1.13605\n",
      "INFO:tensorflow:global_step/sec: 0.559306\n",
      "INFO:tensorflow:examples/sec: 1.11861\n",
      "INFO:tensorflow:global_step/sec: 0.545592\n",
      "INFO:tensorflow:examples/sec: 1.09118\n",
      "INFO:tensorflow:global_step/sec: 0.511998\n",
      "INFO:tensorflow:examples/sec: 1.024\n",
      "INFO:tensorflow:global_step/sec: 0.504407\n",
      "INFO:tensorflow:examples/sec: 1.00881\n",
      "INFO:tensorflow:global_step/sec: 0.520427\n",
      "INFO:tensorflow:examples/sec: 1.04085\n",
      "INFO:tensorflow:global_step/sec: 0.504067\n",
      "INFO:tensorflow:examples/sec: 1.00813\n",
      "INFO:tensorflow:global_step/sec: 0.51078\n",
      "INFO:tensorflow:examples/sec: 1.02156\n",
      "INFO:tensorflow:global_step/sec: 0.521222\n",
      "INFO:tensorflow:examples/sec: 1.04244\n",
      "INFO:tensorflow:global_step/sec: 0.526318\n",
      "INFO:tensorflow:examples/sec: 1.05264\n",
      "INFO:tensorflow:global_step/sec: 0.529009\n",
      "INFO:tensorflow:examples/sec: 1.05802\n",
      "INFO:tensorflow:global_step/sec: 0.526478\n",
      "INFO:tensorflow:examples/sec: 1.05296\n",
      "INFO:tensorflow:global_step/sec: 0.525883\n",
      "INFO:tensorflow:examples/sec: 1.05177\n",
      "INFO:tensorflow:global_step/sec: 0.509304\n",
      "INFO:tensorflow:examples/sec: 1.01861\n",
      "INFO:tensorflow:global_step/sec: 0.489559\n",
      "INFO:tensorflow:examples/sec: 0.979119\n",
      "INFO:tensorflow:global_step/sec: 0.505038\n",
      "INFO:tensorflow:examples/sec: 1.01008\n",
      "INFO:tensorflow:global_step/sec: 0.509539\n",
      "INFO:tensorflow:examples/sec: 1.01908\n",
      "INFO:tensorflow:global_step/sec: 0.513399\n",
      "INFO:tensorflow:examples/sec: 1.0268\n",
      "INFO:tensorflow:global_step/sec: 0.506036\n",
      "INFO:tensorflow:examples/sec: 1.01207\n",
      "INFO:tensorflow:global_step/sec: 0.509397\n",
      "INFO:tensorflow:examples/sec: 1.01879\n",
      "INFO:tensorflow:global_step/sec: 0.543233\n",
      "INFO:tensorflow:examples/sec: 1.08647\n",
      "INFO:tensorflow:global_step/sec: 0.538787\n",
      "INFO:tensorflow:examples/sec: 1.07757\n",
      "INFO:tensorflow:global_step/sec: 0.515892\n",
      "INFO:tensorflow:examples/sec: 1.03178\n",
      "INFO:tensorflow:global_step/sec: 0.521401\n",
      "INFO:tensorflow:examples/sec: 1.0428\n",
      "INFO:tensorflow:global_step/sec: 0.534639\n",
      "INFO:tensorflow:examples/sec: 1.06928\n",
      "INFO:tensorflow:Saving checkpoints for 50 into pretraining_output/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 11.249486.\n",
      "INFO:tensorflow:training_loop marked as finished\n",
      "INFO:tensorflow:***** Running evaluation *****\n",
      "INFO:tensorflow:  Batch size = 8\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running eval on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (8, 128)\n",
      "INFO:tensorflow:  name = input_mask, shape = (8, 128)\n",
      "INFO:tensorflow:  name = masked_lm_ids, shape = (8, 20)\n",
      "INFO:tensorflow:  name = masked_lm_positions, shape = (8, 20)\n",
      "INFO:tensorflow:  name = masked_lm_weights, shape = (8, 20)\n",
      "INFO:tensorflow:  name = next_sentence_labels, shape = (8, 1)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (8, 128)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (64000, 768)\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = cls/predictions/transform/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = cls/predictions/output_bias:0, shape = (64000,)\n",
      "INFO:tensorflow:  name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n",
      "INFO:tensorflow:  name = cls/seq_relationship/output_bias:0, shape = (2,)\n",
      "WARNING:tensorflow:From src/pretraining/run_pretraining.py:267: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
      "\n",
      "WARNING:tensorflow:From src/pretraining/run_pretraining.py:272: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-10-11T22:32:50Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from pretraining_output/model.ckpt-50\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2022-10-11-22:34:11\n",
      "INFO:tensorflow:Saving dict for global step 50: global_step = 50, loss = 11.429996, masked_lm_accuracy = 0.053228803, masked_lm_loss = 10.763401, next_sentence_accuracy = 0.59, next_sentence_loss = 0.6680345\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 50: pretraining_output/model.ckpt-50\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n",
      "INFO:tensorflow:***** Eval results *****\n",
      "INFO:tensorflow:  global_step = 50\n",
      "INFO:tensorflow:  loss = 11.429996\n",
      "INFO:tensorflow:  masked_lm_accuracy = 0.053228803\n",
      "INFO:tensorflow:  masked_lm_loss = 10.763401\n",
      "INFO:tensorflow:  next_sentence_accuracy = 0.59\n",
      "INFO:tensorflow:  next_sentence_loss = 0.6680345\n"
     ]
    }
   ],
   "source": [
    "!python src/pretraining/run_pretraining.py \\\n",
    "  --input_file=dataset/pretraining-dataset/iskan.tfrecord \\\n",
    "  --output_dir=pretraining_output\\\n",
    "  --do_train=True \\\n",
    "  --do_eval=True \\\n",
    "  --bert_config_file=araelectra-base-discriminator/config.json \\\n",
    "  --init_checkpoint=araelectra-base-discriminator/tf-araelectra-base/model.ckpt \\\n",
    "  --train_batch_size=2 \\\n",
    "  --max_seq_length=128 \\\n",
    "  --max_predictions_per_seq=20 \\\n",
    "  --num_train_steps=50 \\\n",
    "  --num_warmup_steps=10 \\\n",
    "  --learning_rate=5e-5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Tensorflow checkpoints to a Pytorch model for later use in fine-tuning the model for downstream tasks, e.g., a question answering system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building PyTorch model from configuration: BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"generator_hidden_size\": 0.33333,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64000\n",
      "}\n",
      "\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "Converting TensorFlow checkpoint from /home/mohammed/AraBERT-QuestionAnswering/pretraining_output/model.ckpt-50\n",
      "Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/embeddings/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/embeddings/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/embeddings/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/embeddings/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]\n",
      "Loading TF weight bert/embeddings/position_embeddings/adam_m with shape [512, 768]\n",
      "Loading TF weight bert/embeddings/position_embeddings/adam_v with shape [512, 768]\n",
      "Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]\n",
      "Loading TF weight bert/embeddings/token_type_embeddings/adam_m with shape [2, 768]\n",
      "Loading TF weight bert/embeddings/token_type_embeddings/adam_v with shape [2, 768]\n",
      "Loading TF weight bert/embeddings/word_embeddings with shape [64000, 768]\n",
      "Loading TF weight bert/embeddings/word_embeddings/adam_m with shape [64000, 768]\n",
      "Loading TF weight bert/embeddings/word_embeddings/adam_v with shape [64000, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_0/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_0/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_0/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_0/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_1/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_1/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_1/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_1/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_10/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_10/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_10/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_10/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_11/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_11/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_11/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_11/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_2/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_2/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_2/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_2/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_3/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_3/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_3/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_3/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_4/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_4/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_4/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_4/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_5/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_5/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_5/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_5/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_6/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_6/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_6/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_6/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_7/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_7/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_7/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_7/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_8/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_8/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_8/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_8/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/key/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/key/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/key/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/key/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/query/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/query/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/query/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/query/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/value/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/value/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/value/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/value/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_9/intermediate/dense/bias/adam_m with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_9/intermediate/dense/bias/adam_v with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel/adam_m with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel/adam_v with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/output/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/output/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_9/output/dense/kernel/adam_m with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_9/output/dense/kernel/adam_v with shape [3072, 768]\n",
      "Loading TF weight bert/pooler/dense/bias with shape [768]\n",
      "Loading TF weight bert/pooler/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight bert/pooler/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight bert/pooler/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/pooler/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight bert/pooler/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight cls/predictions/output_bias with shape [64000]\n",
      "Loading TF weight cls/predictions/output_bias/adam_m with shape [64000]\n",
      "Loading TF weight cls/predictions/output_bias/adam_v with shape [64000]\n",
      "Loading TF weight cls/predictions/transform/LayerNorm/beta with shape [768]\n",
      "Loading TF weight cls/predictions/transform/LayerNorm/beta/adam_m with shape [768]\n",
      "Loading TF weight cls/predictions/transform/LayerNorm/beta/adam_v with shape [768]\n",
      "Loading TF weight cls/predictions/transform/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight cls/predictions/transform/LayerNorm/gamma/adam_m with shape [768]\n",
      "Loading TF weight cls/predictions/transform/LayerNorm/gamma/adam_v with shape [768]\n",
      "Loading TF weight cls/predictions/transform/dense/bias with shape [768]\n",
      "Loading TF weight cls/predictions/transform/dense/bias/adam_m with shape [768]\n",
      "Loading TF weight cls/predictions/transform/dense/bias/adam_v with shape [768]\n",
      "Loading TF weight cls/predictions/transform/dense/kernel with shape [768, 768]\n",
      "Loading TF weight cls/predictions/transform/dense/kernel/adam_m with shape [768, 768]\n",
      "Loading TF weight cls/predictions/transform/dense/kernel/adam_v with shape [768, 768]\n",
      "Loading TF weight cls/seq_relationship/output_bias with shape [2]\n",
      "Loading TF weight cls/seq_relationship/output_bias/adam_m with shape [2]\n",
      "Loading TF weight cls/seq_relationship/output_bias/adam_v with shape [2]\n",
      "Loading TF weight cls/seq_relationship/output_weights with shape [2, 768]\n",
      "Loading TF weight cls/seq_relationship/output_weights/adam_m with shape [2, 768]\n",
      "Loading TF weight cls/seq_relationship/output_weights/adam_v with shape [2, 768]\n",
      "Loading TF weight global_step with shape []\n",
      "Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']\n",
      "Skipping bert/embeddings/LayerNorm/beta/adam_m\n",
      "Skipping bert/embeddings/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']\n",
      "Skipping bert/embeddings/LayerNorm/gamma/adam_m\n",
      "Skipping bert/embeddings/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\n",
      "Skipping bert/embeddings/position_embeddings/adam_m\n",
      "Skipping bert/embeddings/position_embeddings/adam_v\n",
      "Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\n",
      "Skipping bert/embeddings/token_type_embeddings/adam_m\n",
      "Skipping bert/embeddings/token_type_embeddings/adam_v\n",
      "Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\n",
      "Skipping bert/embeddings/word_embeddings/adam_m\n",
      "Skipping bert/embeddings/word_embeddings/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_0/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_0/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_0/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_0/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_0/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_0/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_0/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_0/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_0/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_0/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_0/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_0/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_0/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_0/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_0/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_0/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_0/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_0/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_0/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_0/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_0/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_0/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_0/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_0/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_0/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_0/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_0/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_0/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_1/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_1/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_1/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_1/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_1/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_1/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_1/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_1/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_1/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_1/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_1/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_1/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_1/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_1/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_1/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_1/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_1/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_1/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_1/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_1/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_1/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_1/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_1/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_1/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_1/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_1/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_1/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_1/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_10/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_10/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_10/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_10/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_10/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_10/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_10/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_10/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_10/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_10/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_10/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_10/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_10/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_10/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_10/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_10/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_10/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_10/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_10/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_10/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_10/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_10/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_10/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_10/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_10/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_10/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_10/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_10/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_11/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_11/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_11/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_11/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_11/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_11/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_11/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_11/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_11/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_11/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_11/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_11/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_11/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_11/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_11/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_11/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_11/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_11/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_11/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_11/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_11/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_11/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_11/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_11/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_11/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_11/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_11/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_11/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_2/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_2/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_2/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_2/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_2/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_2/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_2/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_2/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_2/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_2/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_2/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_2/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_2/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_2/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_2/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_2/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_2/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_2/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_2/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_2/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_2/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_2/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_2/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_2/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_2/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_2/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_2/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_2/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_3/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_3/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_3/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_3/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_3/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_3/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_3/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_3/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_3/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_3/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_3/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_3/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_3/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_3/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_3/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_3/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_3/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_3/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_3/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_3/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_3/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_3/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_3/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_3/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_3/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_3/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_3/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_3/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_4/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_4/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_4/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_4/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_4/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_4/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_4/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_4/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_4/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_4/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_4/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_4/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_4/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_4/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_4/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_4/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_4/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_4/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_4/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_4/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_4/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_4/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_4/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_4/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_4/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_4/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_4/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_4/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_5/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_5/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_5/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_5/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_5/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_5/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_5/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_5/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_5/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_5/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_5/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_5/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_5/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_5/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_5/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_5/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_5/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_5/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_5/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_5/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_5/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_5/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_5/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_5/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_5/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_5/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_5/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_5/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_6/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_6/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_6/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_6/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_6/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_6/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_6/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_6/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_6/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_6/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_6/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_6/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_6/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_6/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_6/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_6/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_6/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_6/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_6/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_6/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_6/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_6/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_6/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_6/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_6/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_6/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_6/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_6/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_7/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_7/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_7/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_7/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_7/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_7/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_7/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_7/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_7/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_7/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_7/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_7/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_7/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_7/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_7/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_7/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_7/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_7/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_7/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_7/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_7/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_7/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_7/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_7/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_7/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_7/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_7/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_7/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_8/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_8/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_8/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_8/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_8/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_8/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_8/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_8/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_8/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_8/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_8/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_8/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_8/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_8/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_8/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_8/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_8/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_8/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_8/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_8/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_8/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_8/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_8/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_8/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_8/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_8/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_8/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_8/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_9/attention/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_9/attention/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_9/attention/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_9/attention/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\n",
      "Skipping bert/encoder/layer_9/attention/self/key/bias/adam_m\n",
      "Skipping bert/encoder/layer_9/attention/self/key/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\n",
      "Skipping bert/encoder/layer_9/attention/self/key/kernel/adam_m\n",
      "Skipping bert/encoder/layer_9/attention/self/key/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\n",
      "Skipping bert/encoder/layer_9/attention/self/query/bias/adam_m\n",
      "Skipping bert/encoder/layer_9/attention/self/query/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\n",
      "Skipping bert/encoder/layer_9/attention/self/query/kernel/adam_m\n",
      "Skipping bert/encoder/layer_9/attention/self/query/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\n",
      "Skipping bert/encoder/layer_9/attention/self/value/bias/adam_m\n",
      "Skipping bert/encoder/layer_9/attention/self/value/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\n",
      "Skipping bert/encoder/layer_9/attention/self/value/kernel/adam_m\n",
      "Skipping bert/encoder/layer_9/attention/self/value/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_9/intermediate/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_9/intermediate/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_9/intermediate/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_9/intermediate/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\n",
      "Skipping bert/encoder/layer_9/output/LayerNorm/beta/adam_m\n",
      "Skipping bert/encoder/layer_9/output/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\n",
      "Skipping bert/encoder/layer_9/output/LayerNorm/gamma/adam_m\n",
      "Skipping bert/encoder/layer_9/output/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']\n",
      "Skipping bert/encoder/layer_9/output/dense/bias/adam_m\n",
      "Skipping bert/encoder/layer_9/output/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\n",
      "Skipping bert/encoder/layer_9/output/dense/kernel/adam_m\n",
      "Skipping bert/encoder/layer_9/output/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\n",
      "Skipping bert/pooler/dense/bias/adam_m\n",
      "Skipping bert/pooler/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\n",
      "Skipping bert/pooler/dense/kernel/adam_m\n",
      "Skipping bert/pooler/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['cls', 'predictions', 'output_bias']\n",
      "Skipping cls/predictions/output_bias/adam_m\n",
      "Skipping cls/predictions/output_bias/adam_v\n",
      "Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'beta']\n",
      "Skipping cls/predictions/transform/LayerNorm/beta/adam_m\n",
      "Skipping cls/predictions/transform/LayerNorm/beta/adam_v\n",
      "Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'gamma']\n",
      "Skipping cls/predictions/transform/LayerNorm/gamma/adam_m\n",
      "Skipping cls/predictions/transform/LayerNorm/gamma/adam_v\n",
      "Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'bias']\n",
      "Skipping cls/predictions/transform/dense/bias/adam_m\n",
      "Skipping cls/predictions/transform/dense/bias/adam_v\n",
      "Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'kernel']\n",
      "Skipping cls/predictions/transform/dense/kernel/adam_m\n",
      "Skipping cls/predictions/transform/dense/kernel/adam_v\n",
      "Initialize PyTorch weight ['cls', 'seq_relationship', 'output_bias']\n",
      "Skipping cls/seq_relationship/output_bias/adam_m\n",
      "Skipping cls/seq_relationship/output_bias/adam_v\n",
      "Initialize PyTorch weight ['cls', 'seq_relationship', 'output_weights']\n",
      "Skipping cls/seq_relationship/output_weights/adam_m\n",
      "Skipping cls/seq_relationship/output_weights/adam_v\n",
      "Skipping global_step\n",
      "Save PyTorch model to araelectra-base-discriminator/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!transformers-cli convert --model_type bert \\\n",
    "  --tf_checkpoint pretraining_output/model.ckpt-50 \\\n",
    "  --config araelectra-base-discriminator/config.json \\\n",
    "  --pytorch_dump_output araelectra-base-discriminator/pytorch_model.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('python37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "368899a92c96b77b8737d0c0899584e6db5764acf4a0aebf08a9f2dc81b165b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
